nrow(Bergh)
# Sample size
dim(Bergh)
Bergh$Open  <-  (O1+O2+O3)/3
Bergh$Agree  <-  (A1+A2+A3)/3
Bergh$Prejudice  <-  (EP+SP+DP+HP)/4
attach(Bergh)
## Create mean scores per "construct"
Bergh$Open  <-  (O1+O2+O3)/3
Bergh$Agree  <-  (A1+A2+A3)/3
Bergh$Prejudice  <-  (EP+SP+DP+HP)/4
model1 <- 1
# Structural model
Prejudice ~ b1*Open + b2*Agree
# Covariance structure of exogenous variables
Open ~~ Open + Agree
Agree ~~ Agree
1
model1.fit <- sem(model1,
data = Bergh,
meanstructure  =  FALSE,
estimator = "ML")
model1
# Step 1: Model specification
model1 <- '
# Structural model
Prejudice ~ b1*Open + b2*Agree
# Covariance structure of exogenous variables
Open ~~ Open + Agree
Agree ~~ Agree
'
# Step 2: Model estimation
model1.fit <- sem(model1,
data = Bergh,
meanstructure  =  FALSE,
estimator = "ML")
model1
# Step 2: Model estimation
model1.fit <- sem(model1,
data = Bergh,
meanstructure  =  FALSE,
estimator = "ML")
summary(model1.fit,
rsquare  =  TRUE,
fit.measures  =  TRUE,
standardized  =  TRUE)
# Step 4 Visualize the path model
semPaths(model1.fit,
rotation  =  2,
layout = "tree2",
what = "std",
posCol = "black",
edge.width = 0.5,
style = "Lisrel",
fade = T,
edge.label.position = 0.55)
# Step 4 Visualize the path model
semPaths(model1.fit,
rotation  =  2,
layout = "tree2",
what = "std",
posCol = "black",
edge.width = 1,
style = "Lisrel",
fade = T,
edge.label.position = 0.55)
0.5
# Step 4 Visualize the path model
semPaths(model1.fit,
rotation  =  2,
layout = "tree2",
what = "std",
posCol = "black",
edge.width = 0.5,
style = "Lisrel",
fade = T,
edge.label.position = 0.55)
# Step 5 view Fitted values of the covariance matrix
fitted(model1.fit)
# Step 6 List all parameter values
parameterEstimates(model1.fit)
# Step 7: Further hypothesis testing
# H0: b1=b2
lavTestWald(model1.fit, constraints =  "b1==b2")
library(lavaan)
library(semPlot)
library(MPsychoR)
## 00 Data Input ####
# Select the data
data("Bergh")
attach(Bergh)
## 00 Data Input ####
# Select the data
data("Bergh")
help(Bergh)
help(Bergh)
## 00 Data Input ####
# Select the data
data("Bergh")
View(Bergh)
# Sample size
dim(Bergh) #rows and columns
## Create mean scores per "construct"
Bergh$Open  <-  (O1 + O2 + O3) / 3
Bergh$Agree  <-  (A1 + A2 + A3) / 3
Bergh$Prejudice  <-  (EP + SP + DP + HP) / 4
model1 <- '
# Structural model
Prejudice ~ b1*Open + b2*Agree
# Covariance structure of exogenous variables
Open ~~ Open + Agree
Agree ~~ Agree
'
model1
help(sem)
help(lavaan::sem)
# Step 2: Model estimation
model1.fit <- sem(model1,
data = Bergh,
meanstructure  =  FALSE,
estimator = "ML")
model1.fit
class(model1.fit)
# Step  3:  Evaluate the  model
# Summary
summary(model1.fit,
rsquare  =  TRUE,
fit.measures  =  TRUE,
standardized  =  TRUE)
model1
reticulate::repl_python()
x = 3
y = 2.1
x**y
import pandas as pd
py_install('pandas')
library(reticulate)
conda_install('pandas')
conda install pandas
!conda install pandas
!pip install pandas
library(reticulate)
quit
library(reticulate)
py_install('pandas')
# indicate that we want to use a specific virtualenv
use_virtualenv("r-reticulate")
# import SciPy (will use "r-reticulate" as per call to use_virtualenv)
scipy <- import("scipy")
?nls
tinytex::reinstall_tinytex()
sort( sapply(ls(),function(x){object.size(get(x))}))
1+1
1+2
x <- 1
## 00 Look at the "iris" data ####
# Here we are "telling R" we want to use a dataset called "iris"
data(iris)
# Print the "head" (first 6 lines) if iris data
head(iris)
# The code on the next line will display the help page for the iris data
?iris
boxplot(formula = Sepal.Length ~ Species,
data = iris)
# Create a new variable
my_variable <- c(6.5, 1.35, 3.5)
# Calculate the mean of my_variable
mean(my_variable)
# Calculate the standard deviation of my_variable
sd(my_variable)
## HEADER ####
## Who: Data Science Garage
## https://dsgarage.netlify.app/
## What: 0.1 Bootcamp intro
## Last edited: 2020-06-10
####
## CONTENTS ####
## 00 Look at the "iris" data
## 01 Make a simple graph
## 02 Bootcamp intro exercise 02
## 00 Look at the "iris" data ####
# Here we are "telling R" we want to use a dataset called "iris"
data(iris)
# Print the "head" (first 6 lines) if iris data
head(iris)
# The code on the next line will display the help page for the iris data
?iris
## 01 Make a simple graph ####
# Make a boxplot showing the Sepal.Length for each iris Species
boxplot(formula = Sepal.Length ~ Species,
data = iris)
## 02 Bootcamp intro exercise 02 ####
# New code chunk, my own typing!
# Create a new variable
my_variable <- c(6.5, 1.35, 3.5)
# Calculate the mean of my_variable
mean(my_variable)
# Calculate the standard deviation of my_variable
sd(my_variable)
## 1.1.1 Example script, help, pseudocode  ####
help(mean)
# Try this code in your own script
my_length <- c(101, 122, 97)
mean(x = my_length)
mean(c(4,5,6,7,5))
# add with a "+"
2 + 5
3          +2
# subtract with a "-"
10-15
# multiply with the "*"
6 * 4.2
# divide with the "/"
10/4
2^3
9^(1/2)
sqrt(12.1)
## order of operations
4 + 2 * 3
# test1
4 + (2 * 3)
(4 + 2) * 3
help(c) # We use this a lot - it "combines" numbers
## 1.1.1 Example script, comments, help, pseudocode ####
# Display help page for the function mean
help(mean)
# try this code in your own script
my_length <- c(101, 122, 97) # 3 numerical measures
mean(x = my_length)
## 1.1.2 Math operators ####
# Add with "+"
2 + 5
# Subtract with "-"
10 - 15
# Multiply with "*"
6 * 4.2
10 / 4
# raise to the power of x
2^3
9^(1/2) # same as sqrt()!
# Try this
4 + 2 * 3
# Order control - same
4 + (2 * 3)
# Order control - different...
(4 + 2) * 3
# Try this
6+10                                  # no spaces
7     -5                              # uneven spaces
1.6             /                2.3  # large spaces
16 * 3                                # exactly 1 space
## 1.1.3 Logical Boolean operators ####
# Try this
# simplest example
3 > 5
# 3 is compared to each element
3 < c(1, 2, 3, 4, 5, 6)
TRUE & TRUE # both phrases are true
3 > 1 & 1 < 5 # both phrases are true
TRUE & FALSE # are both true?
FALSE & FALSE # are both true?
x <- c(21, 3, 5, 6, 22)
x
x > 20
# the square brackets act as the index for the data vector
x[x > 20]
# Try this
TRUE # plain true
!FALSE # not false is true!
6 < 5 #definitely false
!(6 < 5) #not false...
!(c(23, 44, 16, 51, 12) > 50)
install.packages("networkD3", dep=T)
sankeyNetwork(Links = links2, Nodes = nodes2, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontSize = 6, nodeWidth = 20,
fontFamily = "sans-serif", iterations = 0)
sankeyNetwork(Links = links2, Nodes = nodes2, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontSize = 8, nodeWidth = 20,
fontFamily = "sans-serif", iterations = 0)
rnorm(100, 10, 1)
dat <- rnorm(100, 10, 1)
hist(dat)
curve(dnorm(x=dat, mean=mean(dat), sd = sd(dat)))
curve(dnorm(x=dat, mean=mean(dat), sd = sd(dat)), add = T)
curve( dnorm(x=dat, mean=mean(dat), sd = sd(dat)), 7,13 )
x <- rnorm(100, 10, 1)
curve( dnorm(x=x, mean=mean(dat), sd = sd(dat)), 7,13 )
curve( dnorm(x=x, mean=mean(dat), sd = sd(dat)), 7,13 , add=T)
hist(dat)
curve( dnorm(x=x, mean=mean(dat), sd = sd(dat)), 7,13 , add=T)
hist(dat, freq=F)
curve( dnorm(x=x, mean=mean(dat), sd = sd(dat)), 7,13 , add=T)
hist(dat, freq=F)
curve( dnorm(x=x, mean=mean(dat), sd = sd(dat)), add=T)
test <- rnorm(100, 10, 1)
hist(dat, freq=F)
hist(test, freq=F)
curve( dnorm(x=x, mean=mean(dat), sd = sd(dat)), add=T)
curve( dnorm(x=x, mean=mean(test), sd = sd(test)), add=T)
test <- rnorm(100, 10, 1)
hist(test, freq=F)
curve( dnorm(x=x, mean=mean(test), sd = sd(test)), add=T)
dnorm(0, mean = 0, sd = 1)
curve( dnorm(x=0, mean=mean(test), sd = sd(test)), add=T)
dnorm(x=0, mean=mean(test), sd = sd(test))
hist(test, freq=F)
curve( dnorm(x=0, mean=mean(test), sd = sd(test)), add=T)
dnorm(0, mean = 0, sd = 1)
dnorm(0, mean = 10, sd = 1)
curve(dnorm(0, mean = 10, sd = 1), add=T)
curve(dnorm(c(-1,0,1), mean = 10, sd = 1), add=T)
curve(dnorm(x = c(-1,0,1), mean = 10, sd = 1), add=T)
x <- c(-1,0,1)
curve(dnorm(x = x, mean = 10, sd = 1), add=T)
curve
(2 * 5) > (2 * 6)
(2 * 5) !> (2 * 6)
!(2 * 5) > (2 * 6)
(2 * 5) > !(2 * 6)
(2 * 6)
!(2 * 6)
(2 * 5)
!(2 * 5) > !(2 * 6)
!(2 * 5) > !(2 * 6)
choose.file()
file.choose()
dat <- read.csv(file.choose())
library(ggplot2)
ggplot(dat (aes(x = survive, y = age))) +
geom_boxplot()
ggplot(dat, (aes(x = survive, y = age))) +
geom_boxplot()
ggplot(dat, (aes(x = survive, y = age))) +
geom_boxplot() +
labs(main = 'mytitle')
ggplot(dat, (aes(x = survive, y = age))) +
geom_boxplot() +
labs(title = 'mytitle')
(dat <- data.frame(
weight = c(44.1, 38.3, 41.1, 41.9, 41.2, 39.7, 44.5, 39.7, 46.1, 39.8,
43.9, 46.9, 35.8, 39.2, 39.6, 41.9, 39.1, 32.0, 32.7, 44.0),
ked = c(9, 4, 15, 11, 10, 8, 12, 12, 6, 11,
12, 13, 8, 11, 19, 19, 12, 7, 8, 14),
trough = c(0.52, 0.74, 0.62, 0.63, 0.22, 0.22, 0.39, 0.94, 0.96, 0.74,
0.73, 0.54, 0.00, 0.61, 0.84, 0.75, 0.45, 0.54, 0.54, 0.00),
shear = c(14.0, 8.0, 14.0, 11.0, 14.0, 5.0, 9.5, 11.0, 6.5, 11.0,
18.5, 11.0, 18.5, 8.0, 8.0, 6.5, 18.5, 15.5, 14.0, 8.0)
))
hist(dat$trough)
lines(density(dat$trough))
hist(dat$trough, freq=F)
lines(density(dat$trough))
curve(dnorm(x,
mean = mean(dat$trough),
sd = sd(dat$trough)),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
hist(dat$trough, freq=F, xlim = -.3, 1.3)
hist(dat$trough, freq=F, xlim = c(-.3, 1.3))
lines(density(dat$trough), col = 'darkblue', lwd = 2)
curve(dnorm(x,
mean = mean(dat$trough),
sd = sd(dat$trough)),
col="red", lwd=2, lty = 2, add=TRUE, yaxt="n")
dbinom
?dbinom
curve(dbinom(x, size = 100, prob = mean = mean(dat$trough), log = FALSE))
curve(dbinom(x, size = 100, prob = mean(dat$trough), log = FALSE))
curve(dbinom(x, size = .5, prob = mean(dat$trough), log = FALSE))
curve(dbinom(x, size = 10, prob = mean(dat$trough), log = FALSE))
mean(dat$trough)
curve(dbinom(x, size = 10, prob = mean(dat$trough), log = T))
curve(dbinom(x, size = 10, prob = mean(dat$trough), log = F))
dbinom(x, size = 10, prob = mean(dat$trough), log = F)
curve(dnorm(x,
mean = mean(dat$trough),
sd = sd(dat$trough)),
col="red", lwd=2, lty = 2, add=TRUE, yaxt="n")
hist(dat$trough, freq=F, xlim = c(-.3, 1.3))
lines(density(dat$trough), col = 'darkblue', lwd = 2)
curve(dnorm(x,
mean = mean(dat$trough),
sd = sd(dat$trough)),
col="red", lwd=2, lty = 2, add=TRUE, yaxt="n")
barplot(c(2,5,8))
barplot(8,5,2)
barplot(c(8,5,2))
a <- c(2,5,8)
b <- c(8,5,2)
barplot(a)
barplot(b)
x <- data.frame(a,b)
geom_barplot(x, aes(x = a)) +
geom_barplot()
ggplot(x, aes(x = a)) +
geom_barplot()
library(ggplot2)
ggplot(x, aes(x = a)) +
geom_barplot()
ggplot(x, aes(x = a)) +
geom_bar()
a <- c(2,5,8)
b <- c(8,5,2)
barplot(a)
barplot(b)
y <- data.frame(a = c('a','a','a','b','b','c'))
ggplot(y, aes(x = a)) +
geom_bar()
?reorder
ggplot(y, aes(x = reorder(x = a, X = c('c', 'b', 'a'))) +
ggplot(y, aes(x = reorder(x = a, X = c('c', 'b', 'a')))) +
geom_bar()
ggplot(y, aes(x = y)) +
geom_bar()
ggplot(y, aes(x = a)) +
geom_bar()
y$a <- factor(y$a, levels = c('c', 'b', 'a'))
ggplot(y, aes(x = a)) +
geom_bar()
y <- data.frame(a = c('a','a','a','b','b','c'))
ggplot(y, aes(x = a)) +
geom_bar()
y$a <- factor(y$a, levels = c('c', 'b', 'a'))
ggplot(y, aes(x = a)) +
geom_bar()
?reorder
177/2.54/12
177/2.54
?cor
x <- c(1,2,3,4,3,2,4)
y <- c(4,8,NA,3,2,4)
cor(x,y)
y <- c(4,8,5, NA,3,2,4)
cor(x,y)
cor(x,y, na.rm=T)
cor(x,y, use='complete.obs')
rnorm(7)
z <- rnorm(7)
i <- data.frame(x,y,z)
cor(i)
cor(i,use='complete.obs')
cor(c(x,y,z), use='complete.obs')
cor(cbind(x,y,z), use='complete.obs')
library(leaps)
?regsubsets
setwd(r'(D:\Dropbox\git-hads\ha-data-science.github.io\pages\harug-files\2021-12-08-LME)')
data <- read.xlsx('blocking.xlsx')
library(nlme)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(lme4)
library(lmerTest)
library(visreg)
library(MuMIn)
library(emmeans)
library(lsmeans)
library(multcomp)
library(multcompView)
library(openxlsx)
library(lsr) # for etaSquared()
library(sjPlot) # for plot_model()
data <- read.xlsx('blocking.xlsx')
data$Block <- factor(data$Block)
data$Traffic <- factor(data$Traffic)
data$Tillage <- factor(data$Tillage, ordered = T,
levels = c('Zero', 'Shallow', 'Deep'))
table(data$Plot); length(table(data$Plot))
summary(data$OM)
interaction.plot(x.factor = data$Traffic,
trace.factor = data$Block,
response = data$OM)  #the blocks look different!
interaction.plot(x.factor = data$Tillage,
trace.factor = data$Block,
response = data$OM)  #the blocks look different!
# diagnose block
# https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize
boxplot(OM ~ Block, data = data)
etaSquared(aov(OM ~ Block, data = data))
etaSquared(aov(OM ~ Traffic, data = data))
etaSquared(aov(OM ~ Tillage, data = data))
boxplot(OM ~ Traffic + Tillage, data = data,
ylim = c(4.3,5.8), xaxt='n', xlab='',
col = c('gray20', 'gray70', 'white'),
at = c(1,2,3,5,6,7,9,10,11))
stripchart(OM ~ Traffic + Tillage, data = data,
ylim = c(4,6), add = T, vertical = T,
method = 'jitter', pch = 16, cex = .5,
at = c(1,2,3,5,6,7,9,10,11), col = 'red')
axis(side = 1, at = c(2,6,10), tick = F, line = -0.5,
labels = c('Deep', 'Shallow', 'Zero'))
axis(side = 1, at = c(6), tick = F, line = 1,
labels = c('Tillage'))
legend(x = 10, y = 5.8,
legend = c('CTF', 'LTF', 'STP'),
pch = 22, pt.bg = c('gray20', 'gray70', 'white'),
title = 'Traffic', bty='n')
#Mixed effect models with random effect: block
lme0 <- lmer(OM ~ Tillage + Traffic + (1|Block), data = data)
plot(lme0) # acceptable
summary(lme0)
anova(lme0)
plot_model(lme0, show.values=TRUE, show.p=TRUE)
#Mixed effect models with random effect: block AND interaction
#If you are interested in the interaction, only consider this one
lme1 <- lmer(OM ~ Tillage * Traffic + (1|Block), data = data)
r.squaredGLMM(lme1)
anova(lme0, lme1)
# replication is so low, we can try all-fixed model
lm0 <- lm(OM ~ Tillage + Traffic + Block, data = data)
anova(lm0)
